# ----- Core -----
ENV=dev

# ----- API -----
API_HOST=0.0.0.0
API_PORT=8000

# SQLite file inside container (volume-backed)
# IMPORTANT: use an absolute path so api+worker share the same volume-backed DB.
DATABASE_URL=sqlite:////data/listen.db

# Upload storage (volume-backed)
UPLOAD_DIR=/data/uploads

# ----- RabbitMQ -----
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672//

# ----- Whisper / Audio -----
# faster-whisper model name or local path (e.g., "base", "small", or "/models/whisper-base-ct2")
WHISPER_MODEL=base

# auto|cpu|cuda
# - Use "cpu" if your worker image doesn't include / can't mount CUDA runtime libraries.
# - Use "cuda" only when the pod has GPU + CUDA libs available.
WHISPER_DEVICE=auto

# Chunk duration for progress updates
AUDIO_CHUNK_SECONDS=15

# ----- OpenWebUI / Ollama-compatible OpenAI API -----
OPENWEBUI_URL=https://OLLAMA_URL/api/v1/chat/completions
OPENWEBUI_API_KEY=
OPENWEBUI_DEFAULT_MODEL=gpt-oss:20b
OPENWEBUI_MAX_TOKENS=65535
OPENWEBUI_TEMPERATURE=0.7

